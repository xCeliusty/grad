{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "OpIv1oXTPuHX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS5u_q1GPuHZ",
    "outputId": "fc19487d-2947-493d-b776-08f983917cf2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape == (105, 9)\n",
      "All timestamps == 105\n",
      "Featured selected: ['CodedDay', 'Zone', 'Weather', 'Temperature', 'Rain', 'Holiday']\n"
     ]
    }
   ],
   "source": [
    "dataset_train = pd.read_excel('Dataset.xlsx')\n",
    "cols = list(dataset_train)[2:8]\n",
    "\n",
    "\n",
    "datelist_train = list(dataset_train['Date'])\n",
    "datelist_train = [dt.datetime.strptime(date, '%m/%d/%Y').date() for date in datelist_train]\n",
    "\n",
    "print('Training set shape == {}'.format(dataset_train.shape))\n",
    "print('All timestamps == {}'.format(len(datelist_train)))\n",
    "print('Featured selected: {}'.format(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMWE_U1kPuHa",
    "outputId": "6a7bf733-c075-48b7-be00-ecce9415c7e4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set == (105, 6).\n",
      "[[ 7.   1.  17.2 12.6  1.   0. ]\n",
      " [ 7.   2.   8.   4.1  0.   0. ]\n",
      " [ 7.   3.   9.7  8.3  0.   0. ]\n",
      " [ 7.   4.  16.  12.4  1.   0. ]\n",
      " [ 7.   5.  16.  12.1  1.   0. ]\n",
      " [ 7.   6.  17.  13.   0.   0. ]\n",
      " [ 7.   7.  16.  12.3  0.   0. ]\n",
      " [ 1.   1.  18.  11.8  1.   0. ]\n",
      " [ 1.   2.   8.4  5.6  1.   0. ]\n",
      " [ 1.   3.  17.1 10.9  0.   0. ]\n",
      " [ 1.   4.  17.3 12.6  1.   0. ]\n",
      " [ 1.   5.  15.9 11.6  1.   0. ]\n",
      " [ 1.   6.  17.5 13.   0.   0. ]\n",
      " [ 1.   7.  16.5 11.5  1.   0. ]\n",
      " [ 2.   1.  19.6 12.6  0.   0. ]\n",
      " [ 2.   2.   7.2  5.2  1.   0. ]\n",
      " [ 2.   3.  18.2 12.4  0.   0. ]\n",
      " [ 2.   4.  18.8 13.4  0.   0. ]\n",
      " [ 2.   5.  17.7 12.9  0.   0. ]\n",
      " [ 2.   6.  19.2 14.2  0.   0. ]\n",
      " [ 2.   7.  17.7 12.2  0.   0. ]\n",
      " [ 3.   1.  21.2 12.8  0.   0. ]\n",
      " [ 3.   2.  10.6  6.   1.   0. ]\n",
      " [ 3.   3.  18.9 12.8  0.   0. ]\n",
      " [ 3.   4.  20.9 14.6  0.   0. ]\n",
      " [ 3.   5.  19.4 14.2  0.   0. ]\n",
      " [ 3.   6.  20.5 15.3  0.   0. ]\n",
      " [ 3.   7.  19.7 13.6  0.   0. ]\n",
      " [ 4.   1.  22.9 13.6  0.   0. ]\n",
      " [ 4.   2.  10.9  7.7  1.   0. ]\n",
      " [ 4.   3.  19.3 12.4  0.   0. ]\n",
      " [ 4.   4.  22.  15.2  0.   0. ]\n",
      " [ 4.   5.  20.6 15.2  0.   0. ]\n",
      " [ 4.   6.  22.4 16.   0.   0. ]\n",
      " [ 4.   7.  21.1 14.4  0.   0. ]\n",
      " [ 5.   1.  14.5 11.3  0.   0. ]\n",
      " [ 5.   2.  10.1  5.7  1.   0. ]\n",
      " [ 5.   3.  16.  11.6  0.   0. ]\n",
      " [ 5.   4.  15.3 12.5  1.   0. ]\n",
      " [ 5.   5.  15.3 12.2  1.   0. ]\n",
      " [ 5.   6.  15.3 13.   0.   0. ]\n",
      " [ 5.   7.  13.2 11.   0.   0. ]\n",
      " [ 6.   1.  17.6 11.5  1.   0. ]\n",
      " [ 6.   2.   5.2  2.7  0.   0. ]\n",
      " [ 6.   3.  18.3 11.9  0.   0. ]\n",
      " [ 6.   4.  16.5 12.   1.   0. ]\n",
      " [ 6.   5.  16.5 12.   1.   0. ]\n",
      " [ 6.   6.  16.2 12.3  1.   0. ]\n",
      " [ 6.   7.  16.2 11.5  0.   0. ]\n",
      " [ 7.   1.  18.  11.5  0.   0. ]\n",
      " [ 7.   2.   5.1  2.1  0.   0. ]\n",
      " [ 7.   3.  18.1 11.6  0.   0. ]\n",
      " [ 7.   4.  18.1 12.5  0.   0. ]\n",
      " [ 7.   5.  18.1 12.5  0.   0. ]\n",
      " [ 7.   6.  17.9 13.2  0.   0. ]\n",
      " [ 7.   7.  16.  12.5  0.   0. ]\n",
      " [ 1.   1.  21.8 12.3  0.   0. ]\n",
      " [ 1.   2.   5.9  2.3  1.   0. ]\n",
      " [ 1.   3.  19.8 13.   0.   0. ]\n",
      " [ 1.   4.  20.6 13.3  0.   0. ]\n",
      " [ 1.   5.  20.6 13.3  0.   0. ]\n",
      " [ 1.   6.  18.9 14.1  0.   0. ]\n",
      " [ 1.   7.  18.3 12.7  0.   0. ]\n",
      " [ 2.   1.  22.7 13.2  0.   0. ]\n",
      " [ 2.   2.   7.3  4.6  0.   0. ]\n",
      " [ 2.   3.  20.4 13.6  0.   0. ]\n",
      " [ 2.   4.  21.6 14.1  0.   0. ]\n",
      " [ 2.   5.  21.6 14.1  0.   0. ]\n",
      " [ 2.   6.  20.9 15.3  0.   0. ]\n",
      " [ 2.   7.  17.7 12.8  0.   0. ]\n",
      " [ 3.   1.  21.7 13.3  0.   0. ]\n",
      " [ 3.   2.   9.4  6.7  1.   0. ]\n",
      " [ 3.   3.  20.7 14.2  0.   0. ]\n",
      " [ 3.   4.  20.9 14.2  0.   0. ]\n",
      " [ 3.   5.  20.9 14.2  0.   0. ]\n",
      " [ 3.   6.  19.4 14.9  0.   0. ]\n",
      " [ 3.   7.  17.9 13.7  0.   0. ]\n",
      " [ 4.   1.  21.9 13.7  0.   0. ]\n",
      " [ 4.   2.   7.7  5.5  0.   0. ]\n",
      " [ 4.   3.  21.8 14.7  0.   0. ]\n",
      " [ 4.   4.  21.4 15.4  0.   0. ]\n",
      " [ 4.   5.  21.4 15.4  0.   0. ]\n",
      " [ 4.   6.  19.6 15.9  0.   0. ]\n",
      " [ 4.   7.  18.6 14.7  0.   0. ]\n",
      " [ 5.   1.  17.7 12.6  1.   0. ]\n",
      " [ 5.   2.   8.6  6.4  0.   0. ]\n",
      " [ 5.   3.  22.6 15.6  0.   0. ]\n",
      " [ 5.   4.  19.9 14.3  0.   0. ]\n",
      " [ 5.   5.  19.9 14.3  0.   0. ]\n",
      " [ 5.   6.  18.4 15.1  0.   0. ]\n",
      " [ 5.   7.  17.4 13.6  0.   0. ]\n",
      " [ 6.   1.  18.6 11.4  0.   0. ]\n",
      " [ 6.   2.  10.4  7.9  0.   0. ]\n",
      " [ 6.   3.  21.9 15.4  0.   0. ]\n",
      " [ 6.   4.  19.9 13.2  0.   0. ]\n",
      " [ 6.   5.  19.9 13.2  0.   0. ]\n",
      " [ 6.   6.  19.2 13.8  0.   0. ]\n",
      " [ 6.   7.  17.8 12.8  0.   0. ]\n",
      " [ 7.   1.  14.8 10.2  1.   0. ]\n",
      " [ 7.   2.   7.2  5.7  1.   0. ]\n",
      " [ 7.   3.  22.5 15.7  0.   0. ]\n",
      " [ 7.   4.  14.  11.4  1.   0. ]\n",
      " [ 7.   5.  14.  11.4  1.   0. ]\n",
      " [ 7.   6.  14.9 11.7  0.   0. ]\n",
      " [ 7.   7.  14.6 11.   1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_train[cols].astype(str)\n",
    "for i in cols:\n",
    "    for j in range(0, len(dataset_train)):\n",
    "        dataset_train[i][j] = dataset_train[i][j].replace(',', '')\n",
    "\n",
    "dataset_train = dataset_train.astype(float)\n",
    "\n",
    "training_set = dataset_train.values\n",
    "\n",
    "print('Shape of training set == {}.'.format(training_set.shape))\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Omy57suSPuHb",
    "outputId": "b184b96b-b639-49fb-f93b-080ff4f8ccde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.54437469],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-1.0617576 ],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.57914051],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [-0.09652342],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.38609367],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 0.86871076],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785],\n",
       "       [ 1.35132785]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "sc_predict = StandardScaler()\n",
    "sc_predict.fit_transform(training_set[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSz7L3w9PuHc",
    "outputId": "4c6269ff-5ebb-44c9-93a3-cb756c95c5db",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "X_train shape == (91, 12, 5).\n",
      "y_train shape == (91, 1).\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# 4 is the new number of days, 7 is the number of zones\n",
    "n_future = 3\n",
    "n_past = 12\n",
    "\n",
    "print(len(training_set_scaled))\n",
    "\n",
    "for i in range(n_past, len(training_set_scaled) - n_future +1):\n",
    "    X_train.append(training_set_scaled[i - n_past:i, 0:dataset_train.shape[1] - 1])\n",
    "    y_train.append(training_set_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print('X_train shape == {}.'.format(X_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ueWD6REoPuHd"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "wLJOpoeqPuHe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(n_past, dataset_train.shape[1]-1)))\n",
    "\n",
    "model.add(LSTM(units=10, return_sequences=False))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0-wm59jPuHf",
    "outputId": "5ff407b8-aed0-426e-c534-1b63c3696a11",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7865\n",
      "Epoch 1: val_loss improved from inf to 1.04971, saving model to weights.h5\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.7865 - val_loss: 1.0497 - lr: 0.0100\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7104\n",
      "Epoch 2: val_loss improved from 1.04971 to 0.80618, saving model to weights.h5\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.7104 - val_loss: 0.8062 - lr: 0.0100\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5020\n",
      "Epoch 3: val_loss improved from 0.80618 to 0.69993, saving model to weights.h5\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5020 - val_loss: 0.6999 - lr: 0.0100\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4489\n",
      "Epoch 4: val_loss improved from 0.69993 to 0.69728, saving model to weights.h5\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4489 - val_loss: 0.6973 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3730\n",
      "Epoch 5: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3730 - val_loss: 0.7895 - lr: 0.0100\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2714\n",
      "Epoch 6: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2714 - val_loss: 0.9960 - lr: 0.0100\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1954\n",
      "Epoch 7: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1954 - val_loss: 1.2591 - lr: 0.0100\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2729\n",
      "Epoch 8: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.2729 - val_loss: 1.3202 - lr: 0.0100\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2054\n",
      "Epoch 9: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2054 - val_loss: 1.3527 - lr: 0.0100\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1425\n",
      "Epoch 10: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1425 - val_loss: 1.3702 - lr: 0.0100\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 11: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1494 - val_loss: 1.3060 - lr: 0.0100\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1529\n",
      "Epoch 12: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1529 - val_loss: 1.2941 - lr: 0.0100\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1459\n",
      "Epoch 13: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1459 - val_loss: 1.3010 - lr: 0.0100\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1385\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.69728\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1385 - val_loss: 1.3607 - lr: 0.0100\n",
      "Epoch 14: early stopping\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "tb = TensorBoard('logs')\n",
    "\n",
    "history = model.fit(X_train, y_train, shuffle=True, epochs=30, callbacks=[es, rlr, mcp, tb], validation_split=0.2, verbose=1, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Xl-slFU_PuHf"
   },
   "outputs": [],
   "source": [
    "datelist_future = pd.date_range(datelist_train[-1], periods=n_future, freq='1d').tolist()\n",
    "\n",
    "datelist_future_ = []\n",
    "for this_timestamp in datelist_future:\n",
    "    datelist_future_.append(this_timestamp.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "5UWx5qQbPuHg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_future = model.predict(X_train[-n_future:])\n",
    "\n",
    "predictions_train = model.predict(X_train[n_past:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "-nzizFOLPuHg",
    "outputId": "fb5676ab-8e20-4a41-b073-fb7b2d9f90d1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>2.963742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>3.321871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>3.643948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date\n",
       "2022-02-07  2.963742\n",
       "2022-02-07  3.321871\n",
       "2022-02-08  3.643948"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def datetime_to_timestamp(x):\n",
    "\n",
    "    return datetime.strptime(x.strftime('%d%m%Y'), '%d%m%Y')\n",
    "\n",
    "\n",
    "y_pred_future = sc_predict.inverse_transform(predictions_future)\n",
    "y_pred_train = sc_predict.inverse_transform(predictions_train)\n",
    "\n",
    "PREDICTIONS_FUTURE = pd.DataFrame(y_pred_future, columns=['Date']).set_index(pd.Series(datelist_future))\n",
    "PREDICTION_TRAIN = pd.DataFrame(y_pred_train, columns=['Date']).set_index(pd.Series(datelist_train[2 * n_past + n_future -1:]))\n",
    "\n",
    "PREDICTION_TRAIN.index = PREDICTION_TRAIN.index.to_series().apply(datetime_to_timestamp)\n",
    "\n",
    "PREDICTION_TRAIN.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "pjmm_y3CPuHh",
    "outputId": "6f5ade93-7838-431b-fe26-237e472cc43f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "\n",
    "START_DATE_FOR_PLOTTING = '2018-06-02'\n",
    "\n",
    "plt.plot(PREDICTIONS_FUTURE.index, PREDICTIONS_FUTURE['Date'], color='r', label='Predicted Traffic')\n",
    "plt.plot(PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:].index, PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:]['Date'], color='orange', label='Training predictions')\n",
    "plt.plot(dataset_train.loc[START_DATE_FOR_PLOTTING:].index, dataset_train.loc[START_DATE_FOR_PLOTTING:]['CodedDay'], color='b', label='Actual Traffic')\n",
    "\n",
    "plt.axvline(x = min(PREDICTIONS_FUTURE.index), color='green', linewidth=2, linestyle='--')\n",
    "\n",
    "plt.grid(which='major', color='#cccccc', alpha=0.5)\n",
    "\n",
    "plt.legend(shadow=True)\n",
    "plt.title('Predcitions and Days', fontsize=12)\n",
    "plt.xlabel('Timeline', fontsize=10)\n",
    "plt.ylabel('Day', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "IWlr30ShPuHh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = pd.DataFrame(dataset_train, columns=cols)\n",
    "dataset_train.index = datelist_train\n",
    "dataset_train.index = pd.to_datetime(dataset_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
